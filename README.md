# Advanced-Machine-Learning

In this work, we look at the problem of unfairness in machine learning models arising out of improper representation of minority groups of people in the training data. In such cases, the ERM model of training is known to result in a model which is unfair to the minority group. We propose an extension of the ERM model which results in a fair prediction, when the training points come from two unknown groups of people. We assume that we do not have any knowledge of the sensitive attribute, i.e. we do not have any knowledge of which group a particular training point belongs to. We only assume that the sample points come from two distinct groups with one these being the majority group and the other being the minority group. We further assume we have knowledge of the size of majority and minority groups in the training data.
